---
title: "Untitled"
author: "Shamira Venturini"
date: "2025-12-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(lme4)
library(tidyverse)
```
```{r}
setwd("/Users/shamiraventurini/PycharmProjects/ICL-PILOT")
df <- read_csv("kideval_ENNI-B1.csv")
```
```{r}
summary(df)
```
```{r}
df$Group
```


```{r}
# Linear Mixed Effects Model (LMM)
# Force a specific reference if needed
df$Group <- as.factor(df$Group)

# Step 2: Now relevel with your reference condition
df$Group <- relevel(df$Group, ref = "SLI")
model <- lm(MLU_Morphemes ~ Group, data = df)
summary(model)

```
Synthetic data with 10 examples have mlu higher than TD kids. 

```{r}
model2 <- lm(VOCD_D_optimum_average ~ Group, data = df)
summary(model2)
```
Synthetic data with 10 examples are lexically too good - even better than TD kids. Although, measure is a bit weak especially on short samples.

```{r}
model3 <- lm(Verbs_Utt ~ Group, data = df)
summary(model3)
```


```{r}
model4 <- lm(retracing ~ Group, data = df)
summary(model4)

```

